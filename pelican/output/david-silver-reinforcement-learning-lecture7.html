
<!DOCTYPE html>
<html lang="ja">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet/less" type="text/css" href="http://englishforhackers.com/theme/stylesheet/style.less">
    <script src="//cdnjs.cloudflare.com/ajax/libs/less.js/2.5.1/less.min.js" type="text/javascript"></script>

  <link rel="stylesheet" type="text/css" href="http://englishforhackers.com/theme/pygments/monokai.min.css">
  <link rel="stylesheet" type="text/css" href="http://englishforhackers.com/theme/font-awesome/css/font-awesome.min.css">

    <link href="http://englishforhackers.com/static/custom.css" rel="stylesheet">

    <link href="http://englishforhackers.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="エンジニア・研究者の英語学習 Atom">


    <link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/images/favicon.ico" type="image/x-icon">

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="index, follow" />

    <!-- Chrome, Firefox OS and Opera -->
    <meta name="theme-color" content="#333333">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#333333">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

<meta name="author" content="Masato Hagiwara" />
<meta name="description" content="「無料でアクセスできる最高の強化学習のコース」と名高い、Google DeepMind / University College London の David Silver 氏による強化学習のコース。こちらのページから、全ての講義スライドと講義ビデオが見られる。以下は、講義7 のメモです。 はじめに これまでは、価値関数から (例えば、ε貪欲法を使って) 方策を直接生成した 価値関数をモデル化する代わりに、方策を直接モデル化する \( \pi_\theta(s, a) = P[a | s, \theta] \) 長所 良い収束性 高次元もしくは行動が連続空間の場合 確率的な方策を学べる 確率的な方策が良い場合 じゃんけん もし、方策が決定的なら、相手にそのことを利用されてしまう 最適な方策は、確率的にランダムな手を出すこと Aliasing (偽信号 -> 2つ以上の状態がお互いに見分けられない場合) が起こる場合 確率的に行動するのが最適 素性のせいで、環境の表現が制限される場合も …" />
<meta name="keywords" content="">
<meta property="og:site_name" content="エンジニア・研究者の英語学習"/>
<meta property="og:title" content="方策勾配法 - Google DeepMind の David Silver 氏による強化学習コース 講義7"/>
<meta property="og:description" content="「無料でアクセスできる最高の強化学習のコース」と名高い、Google DeepMind / University College London の David Silver 氏による強化学習のコース。こちらのページから、全ての講義スライドと講義ビデオが見られる。以下は、講義7 のメモです。 はじめに これまでは、価値関数から (例えば、ε貪欲法を使って) 方策を直接生成した 価値関数をモデル化する代わりに、方策を直接モデル化する \( \pi_\theta(s, a) = P[a | s, \theta] \) 長所 良い収束性 高次元もしくは行動が連続空間の場合 確率的な方策を学べる 確率的な方策が良い場合 じゃんけん もし、方策が決定的なら、相手にそのことを利用されてしまう 最適な方策は、確率的にランダムな手を出すこと Aliasing (偽信号 -> 2つ以上の状態がお互いに見分けられない場合) が起こる場合 確率的に行動するのが最適 素性のせいで、環境の表現が制限される場合も …"/>
<meta property="og:locale" content="ja_JP"/>
<meta property="og:url" content="http://englishforhackers.com/david-silver-reinforcement-learning-lecture7.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2018-09-07 00:00:00-04:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="http://englishforhackers.com/author/masato-hagiwara.html">
<meta property="article:section" content="Reinforcement Learning"/>
<meta property="og:image" content="http://masatohagiwara.net/face.jpg">

  <title>方策勾配法 - Google DeepMind の David Silver 氏による強化学習コース 講義7 &ndash; エンジニア・研究者の英語学習</title>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "ca-pub-7401771876348738",
      enable_page_level_ads: true
    });
  </script>
</head>
<body>
  <aside>
    <div>
      <a href="http://englishforhackers.com">
        <img src="http://masatohagiwara.net/face.jpg" alt="エンジニア・研究者の<br/>英語学習" title="エンジニア・研究者の<br/>英語学習">
      </a>
      <h1><a href="http://englishforhackers.com">エンジニア・研究者の<br/>英語学習</a></h1>

<p>ソフトウェア・エンジニアや研究者のための英語学習情報。講演/トーク・技術記事・論文などの紹介</p>
      <nav>
        <ul class="list">

          <li><a href="http://masatohagiwara.net/" target="_blank">個人ページ</a></li>
          <li><a href="http://www.duolingo.com/" target="_blank">Duolingo</a></li>
          <li><a href="https://docs.google.com/forms/d/e/1FAIpQLSffbTFvdUXJhN4jTOmylcIRvlntKmaYVkIbYPrbBCPm0iC9Sw/viewform?usp=sf_link" target="_blank">お問い合わせ</a></li>
        </ul>
      </nav>

      <ul class="social">
        <li><a class="sc-github" href="https://github.com/mhagiwara" target="_blank"><i class="fa fa-github"></i></a></li>
        <li><a class="sc-twitter" href="https://twitter.com/mhagiwara" target="_blank"><i class="fa fa-twitter"></i></a></li>
        <li><a class="sc-rss" href="feeds/all.atom.xml" target="_blank"><i class="fa fa-rss"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>

    <nav>
      <a href="http://englishforhackers.com">  Home
</a>

      <a href="/archives.html">Archives</a>
      <a href="/categories.html">Categories</a>
      <a href="/tags.html">Tags</a>

      <a href="http://englishforhackers.com/feeds/all.atom.xml">  Atom
</a>

    </nav>

<article class="single">
  <header>
    <h1 id="david-silver-reinforcement-learning-lecture7">方策勾配法 - Google DeepMind の David Silver 氏による強化学習コース 講義7</h1>
    <p>
        Posted on 2018-09-07(金) in <a href="http://englishforhackers.com/category/reinforcement-learning.html">Reinforcement Learning</a>


    </p>
  </header>


  <div>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<p>「無料でアクセスできる最高の強化学習のコース」と名高い、Google DeepMind / University College London の David Silver 氏による強化学習のコース。<a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">こちらのページから、全ての講義スライドと講義ビデオが見られる</a>。以下は、講義7 のメモです。</p>
<ul>
<li>
<p>はじめに</p>
<ul>
<li>これまでは、価値関数から (例えば、ε貪欲法を使って) 方策を直接生成した</li>
<li>価値関数をモデル化する代わりに、方策を直接モデル化する<ul>
<li>\( \pi_\theta(s, a) = P[a | s, \theta] \)</li>
</ul>
</li>
<li>長所<ul>
<li>良い収束性</li>
<li>高次元もしくは行動が連続空間の場合</li>
<li>確率的な方策を学べる</li>
</ul>
</li>
<li>確率的な方策が良い場合<ul>
<li>じゃんけん<ul>
<li>もし、方策が決定的なら、相手にそのことを利用されてしまう</li>
<li>最適な方策は、確率的にランダムな手を出すこと</li>
</ul>
</li>
<li>Aliasing (偽信号 -&gt; 2つ以上の状態がお互いに見分けられない場合) が起こる場合<ul>
<li>確率的に行動するのが最適</li>
<li>素性のせいで、環境の表現が制限される場合も、これに相当</li>
</ul>
</li>
</ul>
</li>
<li>方策の目的関数<ul>
<li>1) 開始状態の値を使う 2) 状態の平均値を使う 3) 1ステップ毎の平均報酬</li>
<li>どれを使っても同じ手法 (方策勾配) になる</li>
</ul>
</li>
<li>方策最適化<ul>
<li>\( J(\theta) \) を最小化する \( \theta \) を見つける</li>
<li>様々な手法が使える<ul>
<li>勾配を使わない手法</li>
<li>勾配を使う手法 (例: 勾配降下法) </li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Finite Difference 方策勾配法</p>
<ul>
<li>勾配の方向に登り、極大解を探す \( \Delta \theta = \alpha_\theta J(\theta) \)</li>
<li>Finite Differences<ul>
<li>各次元について、少し ε だけ値を変えて、\( J(\theta) \) がどう変化するか見る → 勾配の近似</li>
<li>高次元の場合、非効率的</li>
</ul>
</li>
</ul>
</li>
<li>
<p>モンテカルロ方策勾配法</p>
<ul>
<li>尤度比<ul>
<li>方策勾配を解析的に計算する</li>
<li>\( \pi_\theta \) が微分可能で、勾配 \( \nabla_\theta \pi_\theta(s, a) \) が分かっているとすると</li>
<li>\( \nabla_\theta \pi_\theta(s, a) = \pi_\theta(s, a) \nabla_\theta \log \pi_\theta(s, a) \)</li>
<li>スコア関数 \( \nabla_\theta \log \pi_\theta(s, a) \) </li>
<li>これに従うと、尤度最大化 (MLE)</li>
<li>Softmax 方策<ul>
<li>\( \pi_\theta(s, a) \propto \exp{ \phi(s, a)^T \theta )} \)</li>
</ul>
</li>
<li>ガウシアン方策<ul>
<li>平均を、特徴量の線形和で表現 \( \mu(s) = \phi(s)^T \theta \)</li>
</ul>
</li>
</ul>
</li>
<li>One-Step MDP<ul>
<li>尤度比トリックを使う:  \( \nabla_\theta J(\theta) = E_{\pi_\theta}[\nabla_\theta \log \pi_\theta(s, a)r] \) </li>
</ul>
</li>
<li>方策勾配定理<ul>
<li>どの方策目的関数に対しても、\( \nabla_\theta J(\theta) = E_{\pi_\theta}[\nabla_\theta \log \pi_\theta(s, a) Q^{\theta_\pi}(s, a)] \)</li>
</ul>
</li>
<li>Monte-Carlo Policy Gradient (REINFORCE)<ul>
<li>パラメータを勾配降下(上昇)法で更新</li>
<li>\( Q^{\pi_\theta} \) の不偏サンプルとして、\( v_t \) (t から最後までの報酬和) を使う</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Actor-Critic 方策勾配法</p>
<ul>
<li>モンテカルロ方策は、分散がまだ大きい</li>
<li>Critic を使って、行動価値関数を近似</li>
<li>Critic: パラメータ w を使う、Actor: パラメータ θ を使う</li>
<li>Critic: \( Q_w(s, a) \) → 前回の講義と同様に推定</li>
<li>分散を減らすトリック：ベースラインを使う<ul>
<li>期待値を変えずに、ベースラインを減らせる</li>
<li>方策勾配から \( B(s) \) を引く</li>
<li>状態価値関数 \( V^{\pi_\theta} \) をベースラインとして使うと良い</li>
<li>Advantage Function \( A^{\pi_\theta}(s, a) = Q^{\pi_\theta}(s, a) - V^{\pi_\theta}(s) \)<ul>
<li>→ 方策勾配に組み込む</li>
</ul>
</li>
</ul>
</li>
<li>どうやって Advantage Function を推定するか<ul>
<li>方法1. ２つの異なるパラメータを使う</li>
<li>方法2. TD 誤差を使う (期待値が Advantage Function と同じになる)<ul>
<li>\( V(s) \) だけを推定すれば良い</li>
</ul>
</li>
</ul>
</li>
<li>Critic の変種 (異なる時間スケール、ターゲット)<ul>
<li>MC, TD(0), 前向き観点 TD(λ), 後ろ向き観点 TD(λ)</li>
</ul>
</li>
<li>Actor の変種 (異なる時間スケール、ターゲット)<ul>
<li>MC → 利得 \( v_t \) </li>
<li>TD → TD誤差 \( r + \gamma V_v(s_{t+1}) \)</li>
<li>Eligibility Trace</li>
</ul>
</li>
<li>全く偏りの無い方策勾配を求めることも可能 → Compatible function approximator</li>
</ul>
</li>
</ul>
  </div>
  <div class="tag-cloud">
    <p>
    </p>
  </div>


    <div class="addthis_relatedposts_inline">


<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'englishforhackers';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>
      Please enable JavaScript to view comments.

</noscript>
</article>

    <footer>
<p>
  &copy; Masato Hagiwara 2017 - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>
</p>
<p>  Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-nc-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
         src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
  </main>

<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-175204-13', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->



<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " エンジニア・研究者の英語学習 ",
  "url" : "http://englishforhackers.com",
  "image": "http://masatohagiwara.net/face.jpg",
  "description": "ソフトウェア・エンジニアや研究者のための英語学習情報。講演/トーク・技術記事・論文などの紹介"
}
</script>

</body>
</html>