
<!DOCTYPE html>
<html lang="ja">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet/less" type="text/css" href="http://englishforhackers.com/theme/stylesheet/style.less">
    <script src="//cdnjs.cloudflare.com/ajax/libs/less.js/2.5.1/less.min.js" type="text/javascript"></script>

  <link rel="stylesheet" type="text/css" href="http://englishforhackers.com/theme/pygments/monokai.min.css">
  <link rel="stylesheet" type="text/css" href="http://englishforhackers.com/theme/font-awesome/css/font-awesome.min.css">

    <link href="http://englishforhackers.com/static/custom.css" rel="stylesheet">

    <link href="http://englishforhackers.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="エンジニア・研究者の英語学習 Atom">


    <link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/images/favicon.ico" type="image/x-icon">

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="index, follow" />

    <!-- Chrome, Firefox OS and Opera -->
    <meta name="theme-color" content="#333333">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#333333">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

<meta name="author" content="Masato Hagiwara" />
<meta name="description" content="「無料でアクセスできる最高の強化学習のコース」と名高い、Google DeepMind / University College London の David Silver 氏による強化学習のコース。こちらのページから、全ての講義スライドと講義ビデオが見られる。 教科書 An Introduction to Reinforcement Learning 直感的, このコースで参照 Algorithms for Reinforcement Learning 理論, 厳密 強化学習とは 様々な分野と関係 工学、機械学習、神経科学（脳の報酬システムと関係） 機械学習の３つの分類 教師あり学習、教師なし学習、強化学習 他の機械学習アルゴリズムとの違い 教師の代わりに、報酬信号しかない 報酬がすぐに得られるとは限らない 時間の概念が重要。iid (独立同分布)データではない エージェントが環境に影響を及ぼす→データも変わる 強化学習の例 ヘリコプターの曲芸を学習 バックギャモンで世界チャンピオンに勝つ …" />
<meta name="keywords" content="">
<meta property="og:site_name" content="エンジニア・研究者の英語学習"/>
<meta property="og:title" content="強化学習入門 - Google DeepMind の David Silver 氏による強化学習コース 講義1"/>
<meta property="og:description" content="「無料でアクセスできる最高の強化学習のコース」と名高い、Google DeepMind / University College London の David Silver 氏による強化学習のコース。こちらのページから、全ての講義スライドと講義ビデオが見られる。 教科書 An Introduction to Reinforcement Learning 直感的, このコースで参照 Algorithms for Reinforcement Learning 理論, 厳密 強化学習とは 様々な分野と関係 工学、機械学習、神経科学（脳の報酬システムと関係） 機械学習の３つの分類 教師あり学習、教師なし学習、強化学習 他の機械学習アルゴリズムとの違い 教師の代わりに、報酬信号しかない 報酬がすぐに得られるとは限らない 時間の概念が重要。iid (独立同分布)データではない エージェントが環境に影響を及ぼす→データも変わる 強化学習の例 ヘリコプターの曲芸を学習 バックギャモンで世界チャンピオンに勝つ …"/>
<meta property="og:locale" content="ja_JP"/>
<meta property="og:url" content="http://englishforhackers.com/david-silver-reinforcement-learning-lecture1.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2018-09-01 00:00:00-04:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="http://englishforhackers.com/author/masato-hagiwara.html">
<meta property="article:section" content="Reinforcement Learning"/>
<meta property="og:image" content="http://masatohagiwara.net/face.jpg">

  <title>強化学習入門 - Google DeepMind の David Silver 氏による強化学習コース 講義1 &ndash; エンジニア・研究者の英語学習</title>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "ca-pub-7401771876348738",
      enable_page_level_ads: true
    });
  </script>
</head>
<body>
  <aside>
    <div>
      <a href="http://englishforhackers.com">
        <img src="http://masatohagiwara.net/face.jpg" alt="エンジニア・研究者の<br/>英語学習" title="エンジニア・研究者の<br/>英語学習">
      </a>
      <h1><a href="http://englishforhackers.com">エンジニア・研究者の<br/>英語学習</a></h1>

<p>ソフトウェア・エンジニアや研究者のための英語学習情報。講演/トーク・技術記事・論文などの紹介</p>
      <nav>
        <ul class="list">

          <li><a href="http://masatohagiwara.net/" target="_blank">個人ページ</a></li>
          <li><a href="http://www.duolingo.com/" target="_blank">Duolingo</a></li>
          <li><a href="https://docs.google.com/forms/d/e/1FAIpQLSffbTFvdUXJhN4jTOmylcIRvlntKmaYVkIbYPrbBCPm0iC9Sw/viewform?usp=sf_link" target="_blank">お問い合わせ</a></li>
        </ul>
      </nav>

      <ul class="social">
        <li><a class="sc-github" href="https://github.com/mhagiwara" target="_blank"><i class="fa fa-github"></i></a></li>
        <li><a class="sc-twitter" href="https://twitter.com/mhagiwara" target="_blank"><i class="fa fa-twitter"></i></a></li>
        <li><a class="sc-rss" href="feeds/all.atom.xml" target="_blank"><i class="fa fa-rss"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>

    <nav>
      <a href="http://englishforhackers.com">  Home
</a>

      <a href="/archives.html">Archives</a>
      <a href="/categories.html">Categories</a>
      <a href="/tags.html">Tags</a>

      <a href="http://englishforhackers.com/feeds/all.atom.xml">  Atom
</a>

    </nav>

<article class="single">
  <header>
    <h1 id="david-silver-reinforcement-learning-lecture1">強化学習入門 - Google DeepMind の David Silver 氏による強化学習コース 講義1</h1>
    <p>
        Posted on 2018-09-01(土) in <a href="http://englishforhackers.com/category/reinforcement-learning.html">Reinforcement Learning</a>


    </p>
  </header>


  <div>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<p>「無料でアクセスできる最高の強化学習のコース」と名高い、Google DeepMind / University College London の David Silver 氏による強化学習のコース。<a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">こちらのページから、全ての講義スライドと講義ビデオが見られる</a>。</p>
<ul>
<li>
<p>教科書</p>
<ul>
<li>An Introduction to Reinforcement Learning<ul>
<li>直感的, このコースで参照</li>
</ul>
</li>
<li>Algorithms for Reinforcement Learning<ul>
<li>理論, 厳密</li>
</ul>
</li>
</ul>
</li>
<li>
<p>強化学習とは</p>
<ul>
<li>様々な分野と関係</li>
<li>工学、機械学習、神経科学（脳の報酬システムと関係）</li>
<li>機械学習の３つの分類<ul>
<li>教師あり学習、教師なし学習、強化学習</li>
</ul>
</li>
</ul>
</li>
<li>
<p>他の機械学習アルゴリズムとの違い</p>
<ul>
<li>教師の代わりに、報酬信号しかない</li>
<li>報酬がすぐに得られるとは限らない</li>
<li>時間の概念が重要。iid (独立同分布)データではない</li>
<li>エージェントが環境に影響を及ぼす→データも変わる</li>
</ul>
</li>
<li>
<p>強化学習の例</p>
<ul>
<li>ヘリコプターの曲芸を学習</li>
<li>バックギャモンで世界チャンピオンに勝つ</li>
<li>投資ポートフォリオの管理</li>
<li>発電所の制御</li>
<li>人間型ロボットを歩かせる</li>
<li>Atari の複数のゲームをプレイする</li>
<li>Q：強化学習アルゴリズムは、人間の反応時間に比べて速く操作ができるので有利ではないか？ → A: 人間の反応時間に合わせてあるので、公平なはず</li>
</ul>
</li>
<li>
<p>強化学習問題</p>
<ul>
<li>報酬 \( R_t \) --&gt; スカラー値のフィードバック信号。時刻 t においてどのぐらい「うまく行っているか」</li>
<li>報酬の合計の期待値を最大化させるのが目的</li>
<li>報酬に関する仮定：全てのゴールは、累積報酬の期待値を最大化させる問題に帰着できる</li>
</ul>
</li>
<li>
<p>継続的な意思決定</p>
<ul>
<li>目的：将来の報酬の合計を最大化させる行動を選択する</li>
<li>貪欲的に行動するべきではない → 行動が長期にわかって効果を残す。報酬がすぐ得られるとは限らない。</li>
</ul>
</li>
<li>
<p>エージェントと環境</p>
<ul>
<li>エージェントが環境を観察 \( O_t \)</li>
<li>行動 \( A_t \)</li>
<li>報酬 \( R_t \)</li>
</ul>
</li>
<li>
<p>履歴と状態</p>
<ul>
<li>履歴 \( H_t = A_1, O_1, R_1, ..., A_t, O_t, R_t \)</li>
<li>状態 \( S_t = f(H_t) \)</li>
<li>環境状態 \( S^e_t \) → エージェントからは見えない</li>
<li>エージェント状態 \( S^a_t \) </li>
<li>マルコフ性: \( P[S_{t+1} | S_t] = P[S_{t+1} | S_1, ..., S_t] \)<ul>
<li>次の状態は、現在の状態だけに依存する</li>
<li>現在の状態が分かれば、履歴は不要</li>
<li>状態は、未来の十分統計量</li>
<li>ヘリコプターの例：現在の位置、速度、角度、各速度 etc.  位置だけではマルコフ性が成立しない</li>
</ul>
</li>
<li>完全に観察可能な環境<ul>
<li>\( O_t = S^a_t = S^e_t \) → マルコフ決定過程 (Markov Decision Process; MDP)</li>
</ul>
</li>
<li>部分的に観察可能な環境<ul>
<li>部分観測マルコフ決定過程 (Partially Observable MDP; POMDP)</li>
<li>エージェント状態を、環境状態とは独立に構築する必要がある<ul>
<li>方法1: 状態に対する信念（確率分布）を維持する</li>
<li>方法2: 前の状態と、現在の観察から、次の状態を予測する RNN を構築する</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>エージェント</p>
<ul>
<li>方策: エージェントがどのように意思決定するか<ul>
<li>状態 s から行動 a への関数</li>
<li>決定的な方策: \( a = \pi(s) \)</li>
<li>確率的な方策: \( \pi(a | s) = P[A = a | S = s]\)</li>
</ul>
</li>
<li>価値関数: それぞれの状態/行動がどのぐらい良いか<ul>
<li>将来の報酬に対する予測</li>
<li>方策に依存</li>
<li>\( v_\pi(s) = E_\pi[R_t + \gamma R_{t+1} + \gamma^2 R_{t+2} + ... | S_t = s] \)</li>
<li>時間による割引 \( \gamma \) → 遠い未来より近い未来の報酬を優先</li>
</ul>
</li>
<li>モデル: エージェントによる環境の表現（「エージェントが環境がどういう仕組みで動いていると思っているか」）<ul>
<li>遷移モデル: 次の状態を予想する</li>
<li>報酬モデル: 次の報酬を予想する</li>
</ul>
</li>
</ul>
</li>
<li>
<p>エージェントの分類</p>
<ul>
<li>価値ベース: 価値関数を使う</li>
<li>方策ベース: 方策を使う</li>
<li>Actor Critic: 価値関数と方策の両方を使う</li>
<li>モデル無し: 価値関数・方策のどちらかもしくは両方、モデル無し</li>
<li>モデル有り: 価値関数・方策のどちらかもしくは両方、モデル有り</li>
</ul>
</li>
<li>
<p>学習とプランニング</p>
<ul>
<li>強化学習: 環境が未知の状態からスタート、エージェントが環境と相互作用し、方策を改善する</li>
<li>プランニング: 環境のモデルが与えられる、相互作用せずにモデルを使って計算、方策を改善する</li>
</ul>
</li>
<li>
<p>探索と搾取</p>
<ul>
<li>探索: 報酬をあきらめてでも、環境に関する情報を得る</li>
<li>搾取: 既に知っている情報を使い、報酬を最大化する</li>
</ul>
</li>
</ul>
  </div>
  <div class="tag-cloud">
    <p>
    </p>
  </div>


    <div class="addthis_relatedposts_inline">


<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'englishforhackers';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>
      Please enable JavaScript to view comments.

</noscript>
</article>

    <footer>
<p>
  &copy; Masato Hagiwara 2017 - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>
</p>
<p>  Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-nc-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
         src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
  </main>

<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-175204-13', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->



<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " エンジニア・研究者の英語学習 ",
  "url" : "http://englishforhackers.com",
  "image": "http://masatohagiwara.net/face.jpg",
  "description": "ソフトウェア・エンジニアや研究者のための英語学習情報。講演/トーク・技術記事・論文などの紹介"
}
</script>

</body>
</html>